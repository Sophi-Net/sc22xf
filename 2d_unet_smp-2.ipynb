{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a944a9e5-c624-454b-875e-91e3ac87419a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-17 05:12:39.393986: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-17 05:12:40.340245: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/environment/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "from monai.data import DataLoader, Dataset\n",
    "\n",
    "import sys\n",
    "# import itk\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import time\n",
    "\n",
    "import torch\n",
    "# import segmentation_models_pytorch as smp\n",
    "from torch.nn.functional import one_hot\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from monai.losses import DiceLoss\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.metrics import MeanIoU\n",
    "from monai.metrics import ConfusionMatrixMetric\n",
    "from monai.metrics import get_confusion_matrix, compute_confusion_matrix_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6105ee4-d947-4c88-8d89-e0025612b8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available GPUs: 4\n",
      "GPU 1: NVIDIA GeForce RTX 4090\n",
      "GPU 2: NVIDIA GeForce RTX 4090\n",
      "GPU 3: NVIDIA GeForce RTX 4090\n",
      "GPU 4: NVIDIA GeForce RTX 4090\n",
      "GPU 1 Memory: 24217.3125 MB\n",
      "GPU 2 Memory: 24217.3125 MB\n",
      "GPU 3 Memory: 24217.3125 MB\n",
      "GPU 4 Memory: 24217.3125 MB\n"
     ]
    }
   ],
   "source": [
    "import torch.cuda as cuda\n",
    "\n",
    "# 检查CUDA是否可用并获取GPU数量\n",
    "device_count = cuda.device_count()\n",
    "print(f\"Number of available GPUs: {device_count}\")\n",
    "\n",
    "# 获取每个GPU的名称\n",
    "for i in range(device_count):\n",
    "    device_name = cuda.get_device_name(i)\n",
    "    print(f\"GPU {i+1}: {device_name}\")\n",
    "\n",
    "# 获取每个GPU的显存容量\n",
    "for i in range(device_count):\n",
    "    device_properties = cuda.get_device_properties(i)\n",
    "    print(f\"GPU {i+1} Memory: {device_properties.total_memory / 1024 / 1024} MB\")\n",
    "\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24b5cf9c-5051-460f-b2d6-f3b739e04b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Kit19Set(Dataset):\n",
    "#     def __init__(self, datapath, new_size, augmentation=None, preprocessing=None):\n",
    "#         self.datapath = datapath\n",
    "#         self.new_size = new_size\n",
    "#         self.augmentation = augmentation\n",
    "#         self.preprocessing = preprocessing\n",
    "\n",
    "#     def __getitem__(self, i):\n",
    "#         input_img_path = self.datapath+f\"/case_{i:05d}/imaging.nii.gz\"\n",
    "#         input_seg_path = self.datapath+f\"/case_{i:05d}/segmentation.nii.gz\"\n",
    "\n",
    "#         input_image = sitk.ReadImage(input_img_path)\n",
    "\n",
    "#         # Get the current spacing and size of the input image\n",
    "#         input_spacing = input_image.GetSpacing()\n",
    "#         input_size = input_image.GetSize()\n",
    "\n",
    "#         # Compute the desired spacing based on the new size\n",
    "#         new_spacing = [old_sz * old_spc / new_sz for old_sz, old_spc, new_sz in\n",
    "#                        zip(input_size, input_spacing, self.new_size)]\n",
    "\n",
    "#         # Create the resampling transformation\n",
    "#         resampler = sitk.ResampleImageFilter()\n",
    "#         resampler.SetSize(self.new_size)\n",
    "#         resampler.SetOutputSpacing(new_spacing)\n",
    "#         resampler.SetOutputOrigin(input_image.GetOrigin())\n",
    "#         resampler.SetOutputDirection(input_image.GetDirection())\n",
    "\n",
    "#         # Perform the resampling\n",
    "#         output_image = resampler.Execute(input_image)\n",
    "#         output_image = sitk.GetArrayFromImage(output_image)\n",
    "#         output_image = output_image.astype(np.float32)\n",
    "#         output_image = np.transpose(output_image, (2, 1, 0))\n",
    "#         output_image = torch.tensor(output_image)\n",
    "\n",
    "#         input_mask = sitk.ReadImage(input_seg_path)\n",
    "\n",
    "#         # Get the current spacing and size of the input mask\n",
    "#         input_spacing = input_mask.GetSpacing()\n",
    "#         input_size = input_mask.GetSize()\n",
    "\n",
    "#         # Compute the desired spacing based on the new size\n",
    "#         new_spacing = [old_sz * old_spc / new_sz for old_sz, old_spc, new_sz in\n",
    "#                        zip(input_size, input_spacing, self.new_size)]\n",
    "\n",
    "#         # Create the resampling transformation\n",
    "#         resampler = sitk.ResampleImageFilter()\n",
    "#         resampler.SetSize(self.new_size)\n",
    "#         resampler.SetOutputSpacing(new_spacing)\n",
    "#         resampler.SetOutputOrigin(input_mask.GetOrigin())\n",
    "#         resampler.SetOutputDirection(input_mask.GetDirection())\n",
    "\n",
    "#         # Perform the resampling\n",
    "#         output_mask = resampler.Execute(input_mask)\n",
    "#         output_mask = sitk.GetArrayFromImage(output_mask)\n",
    "#         output_mask = output_mask.astype(np.float32)\n",
    "#         output_mask = np.transpose(output_mask, (2, 1, 0))\n",
    "#         # u = np.unique(output_mask)\n",
    "#         # print(output_mask.shape)\n",
    "#         # print(u)\n",
    "#         output_mask = torch.tensor(output_mask)\n",
    "#         # print(torch.sum(torch.eq(output_mask, 2)))\n",
    "#         output_mask = one_hot(output_mask.long(), 3)\n",
    "#         # print(output_mask.shape)\n",
    "#         output_mask = output_mask.permute(3, 0, 1, 2)\n",
    "#         # u = np.unique(output_mask)\n",
    "#         # print(u)\n",
    "#         # print(output_mask.shape)\n",
    "#         # print(torch.all(output_mask[0] == 1))\n",
    "#         # print(torch.all(output_mask[1] == 0))\n",
    "#         # print(torch.all(output_mask[2] == 0))\n",
    "        \n",
    "#         # print(torch.sum(torch.eq(output_mask[0], 1)))\n",
    "#         # print(torch.sum(torch.eq(output_mask[1], 1)))\n",
    "#         # print(torch.sum(torch.eq(output_mask[2], 1)))\n",
    "#         # print(torch.equal(tensor1, tensor2))\n",
    "\n",
    "#         if self.augmentation:\n",
    "#             sample = self.augmentation(image=output_image, mask=output_mask)\n",
    "#             output_image, output_mask = sample['image'], sample['mask']\n",
    "\n",
    "#         if self.preprocessing:\n",
    "#             sample = self.preprocessing(image=output_image, mask=output_mask)\n",
    "#             output_image, output_mask = sample['image'], sample['mask']\n",
    "\n",
    "#         return output_image, output_mask\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return int(210)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Kit19Set(Dataset):\n",
    "    def __init__(self, datapath, augmentation=None, preprocessing=None):\n",
    "        self.datapath = datapath\n",
    "        # self.new_size = new_size\n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        input_img_path = self.datapath+f\"/case_{i:05d}/imaging.nii.gz\"\n",
    "        input_seg_path = self.datapath+f\"/case_{i:05d}/segmentation.nii.gz\"\n",
    "\n",
    "        input_image = sitk.ReadImage(input_img_path)\n",
    "        output_image = sitk.GetArrayFromImage(input_image)\n",
    "        output_image = output_image.astype(np.float32)\n",
    "        output_image = np.transpose(output_image, (2, 1, 0))\n",
    "        output_image = torch.tensor(output_image)\n",
    "\n",
    "        input_mask = sitk.ReadImage(input_seg_path)\n",
    "        output_mask = sitk.GetArrayFromImage(input_mask)\n",
    "        output_mask = output_mask.astype(np.float32)\n",
    "        output_mask = np.transpose(output_mask, (2, 1, 0))\n",
    "\n",
    "        output_mask = torch.tensor(output_mask)\n",
    "        output_mask = one_hot(output_mask.long(), 3)\n",
    "        output_mask = output_mask.permute(3, 0, 1, 2)\n",
    "\n",
    "\n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image=output_image, mask=output_mask)\n",
    "            output_image, output_mask = sample['image'], sample['mask']\n",
    "\n",
    "        if self.preprocessing:\n",
    "            sample = self.preprocessing(image=output_image, mask=output_mask)\n",
    "            output_image, output_mask = sample['image'], sample['mask']\n",
    "\n",
    "        return output_image, output_mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(210)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2c0e70d-416e-45f1-a57e-d53e29394210",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_size = [64, 128, 128]\n",
    "\n",
    "dataset = Kit19Set(\"./data/resized_data_64_128\")\n",
    "# dataset = Kit19Set(\"resized_data\")\n",
    "train_size = int(0.8 * len(dataset))\n",
    "vali_size = len(dataset) - train_size\n",
    "\n",
    "# Use seed at 0 for reproducibility\n",
    "torch.manual_seed(0)\n",
    "train_dataset, vali_dataset = torch.utils.data.random_split(dataset, [train_size, vali_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6a178b7-d754-4f59-b559-1bc1e04aa3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=48)\n",
    "vali_loader = DataLoader(vali_dataset, batch_size=1, shuffle=True, num_workers=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d93c554f-1cc8-422f-9550-04ad54d999e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /home/featurize/.cache/torch/hub/checkpoints/resnet34-333f7ec4.pth\n",
      "100%|██████████| 83.3M/83.3M [00:00<00:00, 542MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use 4 GPUs to train.\n",
      "Use 4 GPUs to train.\n"
     ]
    }
   ],
   "source": [
    "model = smp.Unet(\n",
    "    encoder_name=\"resnet34\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=1,\n",
    "    classes=3,\n",
    ")\n",
    "if device_count > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "    print(f\"Use {device_count} GPUs to train.\")\n",
    "\n",
    "model.to(device)\n",
    "print(f\"Use {device_count} GPUs to train.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a3ccab4-da07-418b-b20f-99e8d6a9f907",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = DiceLoss(include_background=False).to(device)\n",
    "\n",
    "train_dice_metric = DiceMetric(include_background=False, reduction=\"mean\")\n",
    "vali_dice_metric = DiceMetric(include_background=False, reduction=\"mean\")\n",
    "\n",
    "train_mean_iou_metric = MeanIoU(include_background=False, reduction=\"mean\")\n",
    "vali_mean_iou_metric = MeanIoU(include_background=False, reduction=\"mean\")\n",
    "\n",
    "# train_conf_matrix = ConfusionMatrixMetric(include_background=False, reduction=\"mean\")\n",
    "\n",
    "\n",
    "# loss_function = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d521aea-c96a-4449-8c09-a1d65793d8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " ==========================>***********************\t52.98%%"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 42\u001b[0m\n\u001b[1;32m     37\u001b[0m label_slice_batch \u001b[38;5;241m=\u001b[39m label_slice_batch\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m)  \u001b[38;5;66;03m# [4, 3, 128, 128]\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# print(img_slice_batch.shape, label_slice_batch.shape)\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# optimizer.zero_grad()\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_slice_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(out, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# print(out.shape == label_slice_batch.shape)\u001b[39;00m\n",
      "File \u001b[0;32m/environment/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/environment/miniconda3/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:171\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    170\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[:\u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[0;32m--> 171\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather(outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_device)\n",
      "File \u001b[0;32m/environment/miniconda3/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:181\u001b[0m, in \u001b[0;36mDataParallel.parallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparallel_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, replicas, inputs, kwargs):\n\u001b[0;32m--> 181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/environment/miniconda3/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:81\u001b[0m, in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     79\u001b[0m         thread\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m thread \u001b[38;5;129;01min\u001b[39;00m threads:\n\u001b[0;32m---> 81\u001b[0m         \u001b[43mthread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     83\u001b[0m     _worker(\u001b[38;5;241m0\u001b[39m, modules[\u001b[38;5;241m0\u001b[39m], inputs[\u001b[38;5;241m0\u001b[39m], kwargs_tup[\u001b[38;5;241m0\u001b[39m], devices[\u001b[38;5;241m0\u001b[39m], streams[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m/environment/miniconda3/lib/python3.10/threading.py:1096\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1096\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m/environment/miniconda3/lib/python3.10/threading.py:1116\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1117\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1118\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "start = time.time()\n",
    "\n",
    "best_loss = float('inf')\n",
    "train_loss_list, vali_loss_list = [], []\n",
    "train_dice_list, vali_dice_list = [], []\n",
    "train_iou_list, vali_iou_list = [], []\n",
    "\n",
    "epoch = 100\n",
    "true_epoch = 0\n",
    "\n",
    "slice_batch = 8\n",
    "\n",
    "for e in range(epoch):\n",
    "    model.train()\n",
    "\n",
    "    train_loss = 0.0\n",
    "    cm_list = []\n",
    "    # iou = 0\n",
    "    train_dice_metric.reset()\n",
    "    train_mean_iou_metric.reset()\n",
    "    per = 0\n",
    "    tqdm.write(f\"Epoch {e+1}/{epoch}\")\n",
    "\n",
    "    for img,label in train_loader:\n",
    "        torch.cuda.empty_cache()\n",
    "        optimizer.zero_grad()\n",
    "        # print(img.shape, label.shape)\n",
    "        for i in range(0, 64, slice_batch):\n",
    "            img_slice_batch = img[:, i:i+slice_batch, ...].unsqueeze(2).to(device)  # 得到shape [1, 4, 1, 128, 128]\n",
    "            label_slice_batch = label[:, :, i:i+slice_batch, ...].to(device)  # 得到shape [1, 3, 4, 128, 128]\n",
    "            # print(img_slice_batch.shape, label_slice_batch.shape)\n",
    "\n",
    "            # 调整形状以匹配期望的输入\n",
    "            img_slice_batch = img_slice_batch.view(-1, 1, 128, 128)  # [4, 1, 128, 128]\n",
    "            label_slice_batch = label_slice_batch.view(-1, 3, 128, 128)  # [4, 3, 128, 128]\n",
    "            # print(img_slice_batch.shape, label_slice_batch.shape)\n",
    "            \n",
    "            # optimizer.zero_grad()\n",
    "\n",
    "            out = model(img_slice_batch)\n",
    "            out = F.softmax(out, dim=1)\n",
    "            # print(out.shape == label_slice_batch.shape)\n",
    "            out = out.permute(0,2,3,1)\n",
    "            mask = label_slice_batch.permute(0,2,3,1)\n",
    "            # print(out.shape, mask.shape)\n",
    "\n",
    "            loss = loss_function(out, mask)\n",
    "            train_loss += loss.item()\n",
    "            train_dice_metric((out>0.5).float(), mask)\n",
    "            train_mean_iou_metric((out>0.5).float(), mask)\n",
    "\n",
    "            loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        per += 1\n",
    "        percentage = per/len(train_loader)\n",
    "        now = '='*int(percentage*50)+'>'\n",
    "        left = '*'*int((1-percentage)*50)\n",
    "        percen = format(percentage*100, '.2f')\n",
    "        print(\"\\r\", now + left + '\\t' + f\"{percen}\" + '%', end=\"\", flush=True)\n",
    "    epoch_loss = train_loss / (len(train_loader))\n",
    "    train_mean_dice = train_dice_metric.aggregate().item()\n",
    "    train_mean_iou = train_mean_iou_metric.aggregate().item()\n",
    "    # tqdm.write(f\"Train Loss: {epoch_loss}\")\n",
    "    train_loss_list.append(epoch_loss)\n",
    "    train_dice_list.append(train_mean_dice)\n",
    "    train_iou_list.append(train_mean_iou)\n",
    "    print(\"\\ntrain dice loss is: \" + f\"{epoch_loss:.4f}\\t\" + \"train mean dice is: \" + f\"{train_mean_dice:.4f}\\t\" \n",
    "          + \"train mean IoU is: \" + f\"{train_mean_iou:.4f}\")\n",
    "        \n",
    "    model.eval()\n",
    "    eval_loss = 0.0\n",
    "    vali_dice_metric.reset()\n",
    "    vali_mean_iou_metric.reset()\n",
    "    with torch.no_grad():\n",
    "        for img,label in vali_loader:\n",
    "            for i in range(0, 64, slice_batch):\n",
    "                img_slice_batch = img[:, i:i+slice_batch, ...].unsqueeze(2).to(device)  # 得到shape [1, 4, 1, 128, 128]\n",
    "                label_slice_batch = label[:, :, i:i+slice_batch, ...].to(device)  # 得到shape [1, 3, 4, 128, 128]\n",
    "                # print(img_slice_batch.shape, label_slice_batch.shape)\n",
    "\n",
    "                # 调整形状以匹配期望的输入\n",
    "                img_slice_batch = img_slice_batch.view(-1, 1, 128, 128)  # [4, 1, 128, 128]\n",
    "                label_slice_batch = label_slice_batch.view(-1, 3, 128, 128)  # [4, 3, 128, 128]\n",
    "                # print(img_slice_batch.shape, label_slice_batch.shape)\n",
    "\n",
    "                out = model(img_slice_batch)\n",
    "                out = F.softmax(out, dim=1)\n",
    "                # print(out.shape == label_slice_batch.shape)\n",
    "                out = out.permute(0,2,3,1)\n",
    "                mask = label_slice_batch.permute(0,2,3,1)\n",
    "                # print(out.shape, mask.shape)\n",
    "                loss = loss_function(out, mask)\n",
    "                eval_loss += loss.item()\n",
    "                vali_dice_metric((out>0.5).float(), mask)\n",
    "                vali_mean_iou_metric((out>0.5).float(), mask)\n",
    "    vali_loss = eval_loss / (len(vali_loader))\n",
    "    vali_mean_dice = vali_dice_metric.aggregate().item()\n",
    "    vali_mean_iou = vali_mean_iou_metric.aggregate().item()\n",
    "    # tqdm.write(f\"Validation Loss: {vali_loss}\")\n",
    "    vali_loss_list.append(vali_loss)\n",
    "    vali_dice_list.append(vali_mean_dice)\n",
    "    vali_iou_list.append(vali_mean_iou)\n",
    "\n",
    "    print(f\"vali dice loss is: \" + f\"{vali_loss:.4f}\\t\" + \"vali mean dice is: \" + f\"{vali_mean_dice:.4f}\\t\" \n",
    "          + \"vali mean IoU is: \" + f\"{vali_mean_iou:.4f}\\n\")\n",
    "\n",
    "    if vali_loss < best_loss:\n",
    "        best_loss = vali_loss\n",
    "        torch.save(model.state_dict(), \"./2d_adam_0.01/best_model.pth\")\n",
    "\n",
    "    true_epoch += 1\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Costs {end-start}s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9b7ab96-ccdb-4889-8e5d-06329029c1e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "x = range(1, true_epoch+1)\n",
    "# print(true_epoch)\n",
    "loss1, loss2 = train_loss_list, vali_loss_list\n",
    "# print(loss1)\n",
    "plt.title(f'train loss vs vali loss, epoch={true_epoch}, learning rate={learning_rate}, optimizer=Adam')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(x, loss1, label='train loss')\n",
    "plt.plot(x, loss2, label='vali loss')\n",
    "plt.legend()\n",
    "plt.savefig('loss_plot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfb8e2a-ed78-4a42-9b63-8713a61d99d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
